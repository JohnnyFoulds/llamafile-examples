{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2c65c2-545c-4e52-b262-57a6d4dc8699",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 01-01 : Self Container Llamafile Example\n",
    "\n",
    "Tested on AWS SageMaker with an `ml.t3.xlarge` instance.\n",
    "\n",
    "```bash\n",
    "conda create -n llamfile python=3.10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425f6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quantization='Q2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde576d-8112-4430-b442-4709b89fdf4a",
   "metadata": {},
   "source": [
    "## 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "343c3401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: requests in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from requests) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc7e18c-a091-4dbf-a2f2-9906b217fcfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 0.1. Download Llamafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b322426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.75G/2.75G [18:40<00:00, 2.46MiB/s] \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "url = f\"https://huggingface.co/Mozilla/Mistral-7B-Instruct-v0.3-llamafile/resolve/main/Mistral-7B-Instruct-v0.3.{model_quantization}_K.llamafile?download=true\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer hf_itCGxKwnTmhwCGcxvDgfciRyniKMYeZAwhatPk\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "    progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "    \n",
    "    with open(f\"Mistral-7B-Instruct-v0.3.{model_quantization}_K.llamafile\", \"wb\") as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "    progress_bar.close()\n",
    "else:\n",
    "    print(f\"Failed to download file: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500f605-aa54-4db0-885e-a3eb16987cf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 0.2. Install Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ffc82b-10ba-40c7-91f9-514deea81430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai==0.1.16\n",
      "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.17 (from langchain-openai==0.1.16)\n",
      "  Downloading langchain_core-0.2.20-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting openai<2.0.0,>=1.32.0 (from langchain-openai==0.1.16)\n",
      "  Downloading openai-1.35.14-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.1.16)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading langsmith-0.1.88-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16) (24.1)\n",
      "Collecting pydantic<3,>=1 (from langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "     ---------------------------------------- 0.0/125.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 125.2/125.2 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.16)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.16)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.16)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.16)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.16) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai==0.1.16) (4.12.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.1.16)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.16) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai==0.1.16) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai==0.1.16) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai==0.1.16) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai==0.1.16)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai==0.1.16)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading orjson-3.10.6-cp310-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "     ---------------------------------------  51.2/51.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 51.6/51.6 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.17->langchain-openai==0.1.16)\n",
      "  Downloading pydantic_core-2.20.1-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.16) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.16) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\fouldsjo\\appdata\\local\\miniconda3\\envs\\llamfile\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.32.0->langchain-openai==0.1.16) (0.4.6)\n",
      "Downloading langchain_openai-0.1.16-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.1 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 41.0/46.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.1/46.1 kB 578.1 kB/s eta 0:00:00\n",
      "Downloading langchain_core-0.2.20-py3-none-any.whl (371 kB)\n",
      "   ---------------------------------------- 0.0/371.7 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 317.4/371.7 kB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  368.6/371.7 kB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 371.7/371.7 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading openai-1.35.14-py3-none-any.whl (328 kB)\n",
      "   ---------------------------------------- 0.0/328.5 kB ? eta -:--:--\n",
      "   --------------------------------------  327.7/328.5 kB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 328.5/328.5 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-win_amd64.whl (798 kB)\n",
      "   ---------------------------------------- 0.0/798.9 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 471.0/798.9 kB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 737.3/798.9 kB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 798.9/798.9 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.8/86.8 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.88-py3-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.3 kB ? eta -:--:--\n",
      "   ---------------------------------------  133.1/134.3 kB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 134.3/134.3 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "   ---------------------------------------- 0.0/423.9 kB ? eta -:--:--\n",
      "   --------------------------------------  419.8/423.9 kB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 423.9/423.9 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.20.1-cp310-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/1.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.4/1.9 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-win_amd64.whl (145 kB)\n",
      "   ---------------------------------------- 0.0/145.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 145.3/145.3 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp310-cp310-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   --------------------------------------  266.2/269.0 kB 17.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.0/269.0 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.10.6-cp310-none-win_amd64.whl (136 kB)\n",
      "   ---------------------------------------- 0.0/136.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  133.1/136.4 kB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 136.4/136.4 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 774.5 kB/s eta 0:00:00\n",
      "Installing collected packages: tenacity, sniffio, regex, PyYAML, pydantic-core, orjson, jsonpointer, h11, distro, annotated-types, tiktoken, pydantic, jsonpatch, httpcore, anyio, langsmith, httpx, openai, langchain-core, langchain-openai\n",
      "Successfully installed PyYAML-6.0.1 annotated-types-0.7.0 anyio-4.4.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.20 langchain-openai-0.1.16 langsmith-0.1.88 openai-1.35.14 orjson-3.10.6 pydantic-2.8.2 pydantic-core-2.20.1 regex-2024.5.15 sniffio-1.3.1 tenacity-8.5.0 tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai==0.1.16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5414bb-5123-4c62-bb19-a44956f25be5",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24db18e-f170-4c11-baeb-208921fb3a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import stat\n",
    "from typing import Optional\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03379e60-0260-4de5-b6e0-d1253a975de5",
   "metadata": {},
   "source": [
    "## 2. Run Llamafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0408c8-fa51-4d6d-bcac-9a6a78daf2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_quantization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m cwd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Construct the full path to the executable\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m executable_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cwd, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMistral-7B-Instruct-v0.3.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel_quantization\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_K.llamafile\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure the file has execute permissions\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39maccess(executable_path, os\u001b[38;5;241m.\u001b[39mX_OK):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_quantization' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Construct the full path to the executable\n",
    "executable_path = os.path.join(cwd, f'Mistral-7B-Instruct-v0.3.{model_quantization}_K.llamafile')\n",
    "\n",
    "# Ensure the file has execute permissions\n",
    "if not os.access(executable_path, os.X_OK):\n",
    "    st = os.stat(executable_path)\n",
    "    os.chmod(executable_path, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "# Define the arguments separately\n",
    "arguments = ['--port', '8081', '--host', '0.0.0.0', '--nobrowser']\n",
    "\n",
    "# Start the executable in the background\n",
    "llamafile_process = subprocess.Popen(['bash', executable_path] + arguments)\n",
    "print(\"Executable started in the background.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd8cd7-18eb-4ec3-b667-9fa786458d22",
   "metadata": {},
   "source": [
    "## 3. Create LLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f7ffe-9ab5-412f-875a-60e11a0dab99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_chat(\n",
    "        base_url:str='http://localhost:8081/v1',\n",
    "        model:str=\"mozilla/Mistral-7B-Instruct-v0.3-llamafile\",\n",
    "        temperature:float=0.001,\n",
    "        max_retries:int=3,\n",
    "        max_tokens: Optional[int] = None,\n",
    "        timeout:int=20):\n",
    "    \"\"\"\n",
    "    Create the client to interact with vodaGPT\n",
    "    \"\"\"\n",
    "    # set the model_kwargs\n",
    "    model_kwargs = {}\n",
    "    return ChatOpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=\"NA\",\n",
    "        temperature=temperature,\n",
    "        max_retries=max_retries,\n",
    "        max_tokens=max_tokens,\n",
    "        timeout=timeout,\n",
    "        model=model,\n",
    "        model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faea554-cc30-44e0-abd5-37c1cb2897c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the client\n",
    "llm = create_chat(temperature=0.7, max_tokens=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cfa43-6c06-45c8-b8e5-36a33e0c297d",
   "metadata": {},
   "source": [
    "## 4. Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4896c-9378-4871-a3f0-445c92964ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "respone = llm.invoke(\"Why is the sky blue\")\n",
    "print(response.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70602b-b2a4-444b-876a-5ba03436a6f5",
   "metadata": {},
   "source": [
    "## 10. Stop Llamafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd15cb-68bc-417a-a4e0-5fe621bb18fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llamafile_process.terminate()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "kernelspec": {
   "display_name": "vc-knowledgebase-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
