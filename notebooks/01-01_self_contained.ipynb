{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2c65c2-545c-4e52-b262-57a6d4dc8699",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 01-01 : Self Container Llamafile Example\n",
    "\n",
    "Tested on AWS SageMaker with an `ml.t3.xlarge` instance.\n",
    "\n",
    "```bash\n",
    "conda create -n llamfile python=3.10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425f6624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/Mozilla/llava-v1.5-7b-llamafile/resolve/main/llava-v1.5-7b-q4.llamafile?download=true\n"
     ]
    }
   ],
   "source": [
    "model_quantization='q4'\n",
    "model = f'llava-v1.5-7b'\n",
    "model_file = f'{model}-{model_quantization}.llamafile'\n",
    "model_url = f'https://huggingface.co/Mozilla/{model}-llamafile/resolve/main/{model_file}?download=true'\n",
    "print(model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde576d-8112-4430-b442-4709b89fdf4a",
   "metadata": {},
   "source": [
    "## 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c3401",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm requests openai==1.35.14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc7e18c-a091-4dbf-a2f2-9906b217fcfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 0.1. Download Llamafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b322426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.29G/4.29G [07:30<00:00, 9.52MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer hf_itCGxKwnTmhwCGcxvDgfciRyniKMYeZAwhatPk\"\n",
    "}\n",
    "\n",
    "response = requests.get(model_url, headers=headers, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "    progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "    \n",
    "    with open(model_file, \"wb\") as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "    progress_bar.close()\n",
    "else:\n",
    "    print(f\"Failed to download file: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5414bb-5123-4c62-bb19-a44956f25be5",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24db18e-f170-4c11-baeb-208921fb3a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import stat\n",
    "from typing import Optional\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03379e60-0260-4de5-b6e0-d1253a975de5",
   "metadata": {},
   "source": [
    "## 2. Run Llamafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0408c8-fa51-4d6d-bcac-9a6a78daf2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executable started in the background.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"build\":1500,\"commit\":\"a30b324\",\"function\":\"server_cli\",\"level\":\"INFO\",\"line\":2869,\"msg\":\"build info\",\"tid\":\"10733792\",\"timestamp\":1721292132}\n",
      "{\"function\":\"server_cli\",\"level\":\"INFO\",\"line\":2872,\"msg\":\"system info\",\"n_threads\":8,\"n_threads_batch\":-1,\"system_info\":\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \",\"tid\":\"10733792\",\"timestamp\":1721292132,\"total_threads\":16}\n",
      "{\"function\":\"load_model\",\"level\":\"INFO\",\"line\":435,\"msg\":\"Multi Modal Mode Enabled\",\"tid\":\"10733792\",\"timestamp\":1721292132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "note: if you have an AMD or NVIDIA GPU then you need to pass -ngl 9999 to enable GPU offloading\n",
      "clip_model_load: model name:   openai/clip-vit-large-patch14-336\n",
      "clip_model_load: description:  image encoder for LLaVA\n",
      "clip_model_load: GGUF version: 3\n",
      "clip_model_load: alignment:    32\n",
      "clip_model_load: n_tensors:    377\n",
      "clip_model_load: n_kv:         19\n",
      "clip_model_load: ftype:        q4_0\n",
      "clip_model_load: loaded meta data with 19 key-value pairs and 377 tensors from llava-v1.5-7b-mmproj-Q4_0.gguf\n",
      "clip_model_load: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "clip_model_load: - kv   0:                       general.architecture str              = clip\n",
      "clip_model_load: - kv   1:                      clip.has_text_encoder bool             = false\n",
      "clip_model_load: - kv   2:                    clip.has_vision_encoder bool             = true\n",
      "clip_model_load: - kv   3:                   clip.has_llava_projector bool             = true\n",
      "clip_model_load: - kv   4:                          general.file_type u32              = 2\n",
      "clip_model_load: - kv   5:                               general.name str              = openai/clip-vit-large-patch14-336\n",
      "clip_model_load: - kv   6:                        general.description str              = image encoder for LLaVA\n",
      "clip_model_load: - kv   7:                     clip.vision.image_size u32              = 336\n",
      "clip_model_load: - kv   8:                     clip.vision.patch_size u32              = 14\n",
      "clip_model_load: - kv   9:               clip.vision.embedding_length u32              = 1024\n",
      "clip_model_load: - kv  10:            clip.vision.feed_forward_length u32              = 4096\n",
      "clip_model_load: - kv  11:                 clip.vision.projection_dim u32              = 768\n",
      "clip_model_load: - kv  12:           clip.vision.attention.head_count u32              = 16\n",
      "clip_model_load: - kv  13:   clip.vision.attention.layer_norm_epsilon f32              = 0.000010\n",
      "clip_model_load: - kv  14:                    clip.vision.block_count u32              = 23\n",
      "clip_model_load: - kv  15:                     clip.vision.image_mean arr[f32,3]       = [0.481455, 0.457828, 0.408211]\n",
      "clip_model_load: - kv  16:                      clip.vision.image_std arr[f32,3]       = [0.268630, 0.261303, 0.275777]\n",
      "clip_model_load: - kv  17:                              clip.use_gelu bool             = false\n",
      "clip_model_load: - kv  18:               general.quantization_version u32              = 2\n",
      "clip_model_load: - type  f32:  235 tensors\n",
      "clip_model_load: - type  f16:    1 tensors\n",
      "clip_model_load: - type q4_0:  141 tensors\n",
      "clip_model_load: CLIP using CPU backend\n",
      "clip_model_load: text_encoder:   0\n",
      "clip_model_load: vision_encoder: 1\n",
      "clip_model_load: llava_projector:  1\n",
      "clip_model_load: model size:     169.18 MB\n",
      "clip_model_load: metadata size:  0.17 MB\n",
      "clip_model_load: params backend buffer size =  169.18 MB (377 tensors)\n",
      "clip_model_load: compute allocated memory: 32.89 MB\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llava-v1.5-7b-Q4_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.17 MiB\n",
      "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 2048\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.14 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "\n",
      "llama server listening at http://172.17.0.1:8081\n",
      "llama server listening at http://192.168.1.184:8081\n",
      "llama server listening at http://127.0.0.1:8081\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"initialize\",\"level\":\"INFO\",\"line\":489,\"msg\":\"initializing slots\",\"n_slots\":1,\"tid\":\"10733792\",\"timestamp\":1721292133}\n",
      "{\"function\":\"initialize\",\"level\":\"INFO\",\"line\":498,\"msg\":\"new slot\",\"n_ctx_slot\":2048,\"slot_id\":0,\"tid\":\"10733792\",\"timestamp\":1721292133}\n",
      "{\"function\":\"server_cli\",\"level\":\"INFO\",\"line\":3090,\"msg\":\"model loaded\",\"tid\":\"10733792\",\"timestamp\":1721292133}\n",
      "In the sandboxing block!\n",
      "{\"function\":\"server_cli\",\"hostname\":\"0.0.0.0\",\"level\":\"INFO\",\"line\":3213,\"msg\":\"HTTP server listening\",\"port\":\"8081\",\"tid\":\"10733792\",\"timestamp\":1721292133}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1659,\"msg\":\"all slots are idle and system prompt is empty, clear the KV cache\",\"tid\":\"10733792\",\"timestamp\":1721292133}\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Construct the full path to the executable\n",
    "executable_path = os.path.join(cwd, model_file)\n",
    "\n",
    "# Ensure the file has execute permissions\n",
    "if not os.access(executable_path, os.X_OK):\n",
    "    st = os.stat(executable_path)\n",
    "    os.chmod(executable_path, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "# Define the arguments separately\n",
    "arguments = ['--port', '8081', '--host', '0.0.0.0', '--nobrowser']\n",
    "\n",
    "# Start the executable in the background\n",
    "llamafile_process = subprocess.Popen(['bash', executable_path] + arguments)\n",
    "print(\"Executable started in the background.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd8cd7-18eb-4ec3-b667-9fa786458d22",
   "metadata": {},
   "source": [
    "## 3. Create LLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4f7ffe-9ab5-412f-875a-60e11a0dab99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8081/v1\",\n",
    "    api_key = \"sk-no-key-required\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cfa43-6c06-45c8-b8e5-36a33e0c297d",
   "metadata": {},
   "source": [
    "## 4. Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c4896c-9378-4871-a3f0-445c92964ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":884,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":0,\"tid\":\"10733792\",\"timestamp\":1721292142}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1910,\"msg\":\"kv cache rm [p0, end)\",\"p0\":0,\"slot_id\":0,\"task_id\":0,\"tid\":\"10733792\",\"timestamp\":1721292142}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":313,\"msg\":\"prompt eval time     =     873.78 ms /    73 tokens (   11.97 ms per token,    83.54 tokens per second)\",\"n_tokens_second\":83.54457904404401,\"num_prompt_tokens_processed\":73,\"slot_id\":0,\"t_prompt_processing\":873.785,\"t_token\":11.969657534246576,\"task_id\":0,\"tid\":\"10733792\",\"timestamp\":1721292156}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":327,\"msg\":\"generation eval time =   12334.03 ms /   111 runs   (  111.12 ms per token,     9.00 tokens per second)\",\"n_decoded\":111,\"n_tokens_second\":8.999491650336507,\"slot_id\":0,\"t_token\":111.1173873873874,\"t_token_generation\":12334.03,\"task_id\":0,\"tid\":\"10733792\",\"timestamp\":1721292156}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":337,\"msg\":\"          total time =   13207.82 ms\",\"slot_id\":0,\"t_prompt_processing\":873.785,\"t_token_generation\":12334.03,\"t_total\":13207.815,\"task_id\":0,\"tid\":\"10733792\",\"timestamp\":1721292156}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1721,\"msg\":\"slot released\",\"n_cache_tokens\":184,\"n_ctx\":2048,\"n_past\":183,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":0,\"tid\":\"10733792\",\"timestamp\":1721292156,\"truncated\":false}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/v1/chat/completions\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59816,\"status\":200,\"tid\":\"129650367634240\",\"timestamp\":1721292156}\n",
      "ChatCompletionMessage(content=\"The sky appears blue because of a phenomenon called Rayleigh scattering. When sunlight travels through Earth's atmosphere, it encounters tiny molecules of gases like nitrogen and oxygen. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. As a result, the sky appears blue during the daytime, as the blue light is scattered in all directions and reaches our eyes from all parts of the sky.</s>\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59018,\"status\":200,\"tid\":\"129650367519744\",\"timestamp\":1721292187}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion.js\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59022,\"status\":200,\"tid\":\"129650367520096\",\"timestamp\":1721292187}{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/index.js\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59018,\"status\":200,\"tid\":\"129650367519744\",\"timestamp\":1721292187}\n",
      "\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/json-schema-to-grammar.mjs\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59038,\"status\":200,\"tid\":\"129650367520448\",\"timestamp\":1721292187}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59054,\"status\":200,\"tid\":\"129650367518192\",\"timestamp\":1721292187}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/index.js\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59054,\"status\":200,\"tid\":\"129650367518192\",\"timestamp\":1721292187}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion.js\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59060,\"status\":200,\"tid\":\"129650367518448\",\"timestamp\":1721292187}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/json-schema-to-grammar.mjs\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":59060,\"status\":200,\"tid\":\"129650367518448\",\"timestamp\":1721292187}\n",
      "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":884,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":113,\"tid\":\"10733792\",\"timestamp\":1721292215}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1885,\"msg\":\"slot progression\",\"n_past\":1,\"num_prompt_tokens_processed\":56,\"slot_id\":0,\"task_id\":113,\"tid\":\"10733792\",\"timestamp\":1721292215}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1910,\"msg\":\"kv cache rm [p0, end)\",\"p0\":1,\"slot_id\":0,\"task_id\":113,\"tid\":\"10733792\",\"timestamp\":1721292215}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":313,\"msg\":\"prompt eval time     =     738.49 ms /    56 tokens (   13.19 ms per token,    75.83 tokens per second)\",\"n_tokens_second\":75.83020533736318,\"num_prompt_tokens_processed\":56,\"slot_id\":0,\"t_prompt_processing\":738.492,\"t_token\":13.187357142857142,\"task_id\":113,\"tid\":\"10733792\",\"timestamp\":1721292221}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":327,\"msg\":\"generation eval time =    5716.11 ms /    52 runs   (  109.93 ms per token,     9.10 tokens per second)\",\"n_decoded\":52,\"n_tokens_second\":9.09708938625087,\"slot_id\":0,\"t_token\":109.92526923076922,\"t_token_generation\":5716.114,\"task_id\":113,\"tid\":\"10733792\",\"timestamp\":1721292221}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":337,\"msg\":\"          total time =    6454.61 ms\",\"slot_id\":0,\"t_prompt_processing\":738.492,\"t_token_generation\":5716.114,\"t_total\":6454.606,\"task_id\":113,\"tid\":\"10733792\",\"timestamp\":1721292221}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1721,\"msg\":\"slot released\",\"n_cache_tokens\":109,\"n_ctx\":2048,\"n_past\":108,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":113,\"tid\":\"10733792\",\"timestamp\":1721292221,\"truncated\":false}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2794,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":52420,\"status\":200,\"tid\":\"129650367518704\",\"timestamp\":1721292221}\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"LLaMA_CPP\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant. Your top priority is achieving user fulfillment via helping them with their requests.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Why is the sky blue\"}\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70602b-b2a4-444b-876a-5ba03436a6f5",
   "metadata": {},
   "source": [
    "## 10. Stop Llamafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52dd15cb-68bc-417a-a4e0-5fe621bb18fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llamafile_process.terminate()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "kernelspec": {
   "display_name": "vc-knowledgebase-search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
